# ============================================================================
# PicoClaw Atlas — User Configuration
# ============================================================================
# This file defines ALL user-configurable variables for atlas-install.sh.
# The installer reads these values to skip or pre-fill wizard prompts.
#
# HOW TO USE:
#   1. Copy this file:  cp config.yaml config.local.yaml
#   2. Edit config.local.yaml with your values
#   3. Run installer:   bash atlas-install.sh --config config.local.yaml
#
# VALUES:
#   - Strings must be quoted
#   - Booleans: true / false (lowercase, unquoted)
#   - Numbers: unquoted integers or floats
#   - Empty string "" means "not set" (installer will prompt)
#
# SECRETS:
#   - NEVER commit API keys to version control
#   - config.local.yaml is in .gitignore
# ============================================================================

# --------------------------------------------------------------------------
# Installation Method
# --------------------------------------------------------------------------
# "binary" = download pre-built release (fast, recommended)
# "source" = clone repo and compile with Go (requires ~10 min + 2GB RAM)
install_method: "binary"

# --------------------------------------------------------------------------
# System Performance Optimizer
# --------------------------------------------------------------------------
# Applies deep kernel/network/IO tuning (TCP BBR, sysctl, zram, I/O scheduler,
# SSD TRIM, tmpfs, DNS, journald, disabled services, IRQ balance, MGLRU, KSM).
# WARNING: Requires mandatory reboot after installation when enabled.
performance_optimizer: true

# --------------------------------------------------------------------------
# LLM Provider
# --------------------------------------------------------------------------
# Supported: "openrouter", "zhipu", "openai", "gemini", "groq", "vllm", "ollama"
# Note: Anthropic models are routed through OpenRouter (set provider to "openrouter"
#       and pick a Claude model below).
llm:
  provider: "openrouter"
  api_key: ""
  api_base: ""                           # Auto-set per provider; override for vllm/custom
  model: ""                              # See model lists below

  # --- Generation defaults ---
  max_tokens: 8192                       # Max tokens per LLM response
  temperature: 0.7                       # Sampling temperature (0.0 = deterministic, 1.0 = creative)
  max_tool_iterations: 20               # Max consecutive tool-call rounds per message

# --- Model reference (pick one and paste into llm.model above) ---
#
# OpenRouter models:
#   "anthropic/claude-sonnet-4.5"                  (recommended)
#   "anthropic/claude-opus-4.6"
#   "anthropic/claude-opus-4.5"
#   "anthropic/claude-sonnet-4"
#   "openai/gpt-5.2"
#   "openai/gpt-5.1"
#   "openai/gpt-5"
#   "openai/gpt-5-mini"
#   "google/gemini-3-pro-preview"
#   "google/gemini-3-flash-preview"
#   "google/gemini-2.5-flash"
#   "google/gemini-2.5-pro"
#   "deepseek/deepseek-r1"
#   "deepseek/deepseek-v3-0324"
#   "meta-llama/llama-4-maverick"
#   "qwen/qwen3-235b-a22b"
#
# Anthropic (via OpenRouter):
#   "anthropic/claude-sonnet-4.5"                  (recommended)
#   "anthropic/claude-opus-4.6"
#   "anthropic/claude-opus-4.5"
#   "anthropic/claude-opus-4.1"
#   "anthropic/claude-opus-4"
#   "anthropic/claude-sonnet-4"
#   "anthropic/claude-haiku-4.5"
#
# Zhipu models:
#   "glm-5"                                        (recommended)
#   "glm-4.7"
#   "glm-4.7-flashx"
#   "glm-4.7-flash"
#   "glm-4.6"
#   "glm-4.5"
#   "glm-4.5-x"
#   "glm-4.5-air"
#   "glm-4.5-airx"
#   "glm-4.5-flash"
#   "glm-4-32b-0414-128k"
#   "glm-4.6v"
#   "glm-4.6v-flashx"
#   "glm-4.5v"
#   "glm-4.6v-flash"
#
# OpenAI models:
#   "gpt-5.2"                                      (recommended)
#   "gpt-5.1"
#   "gpt-5"
#   "gpt-5-mini"
#   "gpt-5-nano"
#   "gpt-4.1"
#   "gpt-4.1-mini"
#   "gpt-4.1-nano"
#   "o3"
#   "o4-mini"
#   "gpt-4o"
#
# Gemini models:
#   "gemini-2.5-flash"                             (recommended)
#   "gemini-3-pro-preview"
#   "gemini-3-flash-preview"
#   "gemini-2.5-pro"
#   "gemini-2.5-flash-lite"
#   "gemini-2.0-flash"
#
# Groq models:
#   "llama-3.3-70b-versatile"                      (recommended)
#   "llama-3.1-8b-instant"
#   "openai/gpt-oss-120b"
#   "openai/gpt-oss-20b"
#   "meta-llama/llama-4-maverick-17b-128e-instruct"
#   "meta-llama/llama-4-scout-17b-16e-instruct"
#   "qwen/qwen3-32b"
#   "moonshotai/kimi-k2-instruct-0905"
#
# Ollama models (local):
#   "qwen3:4b"          2.5GB  (recommended)
#   "phi4-mini"          3.3GB
#   "nanbeige4.1:3b"    2.0GB
#   "gemma3:4b"          3.3GB
#   "qwen3:1.7b"        1.0GB
#   "smollm3:3b"        2.0GB
#   "lfm2.5:1.2b"       0.8GB
#   "qwen3:0.6b"        0.4GB
#   "deepseek-r1:1.5b"  1.0GB
#   "gemma3:1b"          0.8GB
#   "llama3.2:3b"       2.0GB
#   "mistral:7b"        4.1GB  (needs 8GB+ RAM)
#   "qwen3:8b"          4.7GB  (needs 8GB+ RAM)

# --------------------------------------------------------------------------
# Ollama (Local LLM)
# --------------------------------------------------------------------------
# Only used when llm.provider is "ollama".
ollama:
  enabled: false
  model: "qwen3:4b"                     # Base model to pull from Ollama registry
  num_ctx: 8192                          # Context window size (minimum: 8192)
  host: "127.0.0.1"                      # Ollama API listen address
  port: 11434                            # Ollama API listen port

# --------------------------------------------------------------------------
# Voice Transcription (Groq Whisper)
# --------------------------------------------------------------------------
# Optional Groq API key for voice message transcription.
# Skipped if primary provider is already Groq (uses same key).
groq_voice:
  api_key: ""

# --------------------------------------------------------------------------
# Web Search (Brave)
# --------------------------------------------------------------------------
brave_search:
  api_key: ""
  max_results: 5                         # Results per search query (1-20)

# --------------------------------------------------------------------------
# Channels — Messaging Platforms
# --------------------------------------------------------------------------

# --- Telegram ---
telegram:
  enabled: false
  token: ""                              # Bot token from @BotFather
  user_id: ""                            # Your numeric user ID (e.g. "5323045369")
  username: ""                           # Your username without @ (e.g. "johndoe")

# --- Discord ---
discord:
  enabled: false
  token: ""                              # Bot token from Discord Developer Portal
  user_id: ""                            # Your numeric user ID
  username: ""                           # Your username without # (e.g. "johndoe")

# --- WhatsApp ---
whatsapp:
  enabled: false
  bridge_port: 3001                      # WebSocket bridge port (1-65535)
  user_id: ""                            # Phone number, international format (e.g. "+14155551234")

# --- Feishu / Lark ---
feishu:
  enabled: false
  app_id: ""
  app_secret: ""
  encrypt_key: ""                        # Optional
  verification_token: ""                 # Optional

# --- MaixCAM ---
maixcam:
  enabled: false
  host: "0.0.0.0"
  port: 18790

# --------------------------------------------------------------------------
# Gateway
# --------------------------------------------------------------------------
gateway:
  host: "0.0.0.0"
  port: 18790

# --------------------------------------------------------------------------
# FTP Server (vsftpd)
# --------------------------------------------------------------------------
ftp:
  enabled: false
  user: "root"
  password: ""                           # Min 8 characters
  port: 21                               # FTP control port (1-65535)
  pasv_min_port: 40000                   # Passive mode range start
  pasv_max_port: 40100                   # Passive mode range end
  tls: true                              # Enable TLS encryption (self-signed cert)

# --------------------------------------------------------------------------
# Systemd Service
# --------------------------------------------------------------------------
# Installs picoclaw-gateway.service + watchdog timer + @reboot cron fallback.
systemd:
  enabled: true

# --------------------------------------------------------------------------
# Automatic Backups
# --------------------------------------------------------------------------
backup:
  enabled: true
  interval_days: 6                       # Days between automatic backups
  max_keep: 18                           # Max snapshots to retain (oldest purged)

# --------------------------------------------------------------------------
# Atlas Skills Repository
# --------------------------------------------------------------------------
# Dynamically discovers and installs all skills from github.com/pr0ace/atlas.
atlas_skills:
  enabled: true
